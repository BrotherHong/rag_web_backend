# ğŸš€ éƒ¨ç½²æŒ‡å—

## éƒ¨ç½²æ¶æ§‹é¸æ“‡

### é–‹ç™¼ç’°å¢ƒ
```
æœ¬åœ°é–‹ç™¼ â†’ Pythonè™›æ“¬ç’°å¢ƒ â†’ SQLite/PostgreSQL
```

### æ¸¬è©¦ç’°å¢ƒ
```
Docker Compose â†’ å®¹å™¨åŒ–æœå‹™ â†’ å…§éƒ¨ç¶²è·¯æ¸¬è©¦
```

### ç”Ÿç”¢ç’°å¢ƒ
```
Docker + Nginx + PostgreSQL + Redis + Qdrant
æˆ–
Kubernetes å¢é›†éƒ¨ç½²ï¼ˆå¤§è¦æ¨¡ï¼‰
```

---

## 1. Docker éƒ¨ç½²ï¼ˆæ¨è–¦ï¼‰

### Dockerfile

```dockerfile
# docker/Dockerfile
FROM python:3.11-slim

# è¨­å®šå·¥ä½œç›®éŒ„
WORKDIR /app

# å®‰è£ç³»çµ±ä¾è³´
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    postgresql-client \
    libpq-dev \
    curl \
    && rm -rf /var/lib/apt/lists/*

# è¤‡è£½ä¾è³´æª”æ¡ˆ
COPY requirements.txt .

# å®‰è£ Python ä¾è³´
RUN pip install --no-cache-dir -r requirements.txt

# è¤‡è£½æ‡‰ç”¨ç¨‹å¼
COPY . .

# å»ºç«‹å¿…è¦ç›®éŒ„
RUN mkdir -p /app/uploads /app/logs

# è¨­å®šç’°å¢ƒè®Šæ•¸
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# å•Ÿå‹•å‘½ä»¤
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

### Docker Compose å®Œæ•´é…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  # PostgreSQL è³‡æ–™åº«
  postgres:
    image: postgres:16-alpine
    container_name: rag_postgres
    restart: always
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-rag_db}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init_db.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    networks:
      - rag_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis
  redis:
    image: redis:7-alpine
    container_name: rag_redis
    restart: always
    command: >
      redis-server
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --requirepass ${REDIS_PASSWORD:-redis123}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - rag_network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Qdrant å‘é‡è³‡æ–™åº«
  qdrant:
    image: qdrant/qdrant:latest
    container_name: rag_qdrant
    restart: always
    volumes:
      - qdrant_data:/qdrant/storage
    ports:
      - "6333:6333"
      - "6334:6334"
    networks:
      - rag_network
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334

  # FastAPI å¾Œç«¯
  backend:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: rag_backend
    restart: always
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-rag_db}
      - REDIS_URL=redis://:${REDIS_PASSWORD:-redis123}@redis:6379/0
      - QDRANT_URL=http://qdrant:6333
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD:-redis123}@redis:6379/1
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD:-redis123}@redis:6379/2
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      qdrant:
        condition: service_started
    networks:
      - rag_network

  # Celery Worker
  celery_worker:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: rag_celery_worker
    restart: always
    command: celery -A app.tasks.celery_app worker --loglevel=info --concurrency=4 --max-tasks-per-child=100
    volumes:
      - ./uploads:/app/uploads
      - ./logs:/app/logs
    environment:
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-rag_db}
      - REDIS_URL=redis://:${REDIS_PASSWORD:-redis123}@redis:6379/0
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD:-redis123}@redis:6379/1
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD:-redis123}@redis:6379/2
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - QDRANT_URL=http://qdrant:6333
    depends_on:
      - postgres
      - redis
      - backend
    networks:
      - rag_network

  # Flower (Celery ç›£æ§)
  flower:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: rag_flower
    restart: always
    command: celery -A app.tasks.celery_app flower --port=5555 --basic_auth=${FLOWER_USER:-admin}:${FLOWER_PASSWORD:-admin123}
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD:-redis123}@redis:6379/1
      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD:-redis123}@redis:6379/2
    depends_on:
      - redis
      - celery_worker
    networks:
      - rag_network

  # Nginx åå‘ä»£ç†
  nginx:
    image: nginx:alpine
    container_name: rag_nginx
    restart: always
    volumes:
      - ./docker/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./docker/ssl:/etc/nginx/ssl:ro  # SSL æ†‘è­‰
      - nginx_logs:/var/log/nginx
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - backend
    networks:
      - rag_network

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  qdrant_data:
    driver: local
  nginx_logs:
    driver: local

networks:
  rag_network:
    driver: bridge
```

---

### Nginx é…ç½®

```nginx
# docker/nginx.conf
events {
    worker_connections 1024;
}

http {
    upstream backend {
        server backend:8000;
    }

    # é€Ÿç‡é™åˆ¶
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/m;
    
    # HTTP é‡å®šå‘åˆ° HTTPS
    server {
        listen 80;
        server_name your-domain.com;
        
        location / {
            return 301 https://$server_name$request_uri;
        }
    }
    
    # HTTPS ä¸»ä¼ºæœå™¨
    server {
        listen 443 ssl http2;
        server_name your-domain.com;
        
        # SSL æ†‘è­‰
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers HIGH:!aNULL:!MD5;
        
        # å®‰å…¨æ¨™é ­
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Strict-Transport-Security "max-age=31536000" always;
        
        # æª”æ¡ˆä¸Šå‚³å¤§å°é™åˆ¶
        client_max_body_size 100M;
        
        # API è·¯ç”±
        location /api/ {
            limit_req zone=api_limit burst=20 nodelay;
            
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # WebSocket æ”¯æ´
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            
            # è¶…æ™‚è¨­å®š
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }
        
        # å‰ç«¯éœæ…‹æª”æ¡ˆ
        location / {
            root /usr/share/nginx/html;
            try_files $uri $uri/ /index.html;
        }
        
        # å¥åº·æª¢æŸ¥
        location /health {
            proxy_pass http://backend/health;
            access_log off;
        }
    }
}
```

---

## 2. ç’°å¢ƒè®Šæ•¸é…ç½®

### .env.production

```env
# æ‡‰ç”¨è¨­å®š
APP_NAME=RAG Knowledge Base
DEBUG=False
API_V1_PREFIX=/api

# å®‰å…¨é‡‘é‘°ï¼ˆè«‹ä½¿ç”¨ openssl rand -hex 32 ç”Ÿæˆï¼‰
SECRET_KEY=your-super-secret-key-change-this-in-production
JWT_SECRET_KEY=your-jwt-secret-key-change-this-too
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=1440

# è³‡æ–™åº«
POSTGRES_DB=rag_db
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your-strong-password
DATABASE_URL=postgresql+asyncpg://postgres:your-strong-password@postgres:5432/rag_db
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=40

# Redis
REDIS_PASSWORD=redis-strong-password
REDIS_URL=redis://:redis-strong-password@redis:6379/0
REDIS_CACHE_TTL=3600

# Celery
CELERY_BROKER_URL=redis://:redis-strong-password@redis:6379/1
CELERY_RESULT_BACKEND=redis://:redis-strong-password@redis:6379/2

# OpenAI
OPENAI_API_KEY=sk-your-openai-api-key
OPENAI_MODEL=gpt-4
OPENAI_EMBEDDING_MODEL=text-embedding-ada-002

# Qdrant
QDRANT_URL=http://qdrant:6333
QDRANT_API_KEY=
QDRANT_COLLECTION=rag_documents

# æª”æ¡ˆä¸Šå‚³
MAX_FILE_SIZE=52428800
ALLOWED_EXTENSIONS=.pdf,.docx,.txt,.md
UPLOAD_DIR=/app/uploads

# CORS
CORS_ORIGINS=https://your-domain.com,https://www.your-domain.com

# Flowerï¼ˆCelery ç›£æ§ï¼‰
FLOWER_USER=admin
FLOWER_PASSWORD=flower-admin-password
```

---

## 3. éƒ¨ç½²æ­¥é©Ÿ

### æ­¥é©Ÿ 1: æº–å‚™ä¼ºæœå™¨

```bash
# æ›´æ–°ç³»çµ±
sudo apt update && sudo apt upgrade -y

# å®‰è£ Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# å®‰è£ Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# é©—è­‰å®‰è£
docker --version
docker-compose --version
```

---

### æ­¥é©Ÿ 2: éƒ¨ç½²å¾Œç«¯

```bash
# 1. Clone å°ˆæ¡ˆ
cd /opt
sudo git clone https://github.com/BrotherHong/rag_web_backend.git
cd rag_web_backend

# 2. è¨­å®šç’°å¢ƒè®Šæ•¸
sudo cp .env.example .env.production
sudo nano .env.production  # ç·¨è¼¯ä¸¦å¡«å…¥å¯¦éš›å€¼

# 3. å»ºç«‹å¿…è¦ç›®éŒ„
sudo mkdir -p uploads logs docker/ssl

# 4. ç”Ÿæˆ SSL æ†‘è­‰ï¼ˆæ¸¬è©¦ç”¨ï¼‰
sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
  -keyout docker/ssl/key.pem \
  -out docker/ssl/cert.pem

# 5. å»ºæ§‹ä¸¦å•Ÿå‹•æœå‹™
sudo docker-compose --env-file .env.production up -d --build

# 6. æŸ¥çœ‹æ—¥èªŒ
sudo docker-compose logs -f backend

# 7. åŸ·è¡Œè³‡æ–™åº«é·ç§»
sudo docker-compose exec backend alembic upgrade head

# 8. å»ºç«‹è¶…ç´šç®¡ç†å“¡
sudo docker-compose exec backend python scripts/create_admin.py
```

---

### æ­¥é©Ÿ 3: é©—è­‰éƒ¨ç½²

```bash
# æª¢æŸ¥æ‰€æœ‰å®¹å™¨ç‹€æ…‹
sudo docker-compose ps

# é æœŸè¼¸å‡ºï¼š
# NAME                STATUS              PORTS
# rag_backend         Up                  0.0.0.0:8000->8000/tcp
# rag_postgres        Up (healthy)        0.0.0.0:5432->5432/tcp
# rag_redis           Up (healthy)        0.0.0.0:6379->6379/tcp
# rag_qdrant          Up                  0.0.0.0:6333->6333/tcp
# rag_celery_worker   Up
# rag_flower          Up                  0.0.0.0:5555->5555/tcp
# rag_nginx           Up                  0.0.0.0:80->80/tcp, 0.0.0.0:443->443/tcp

# æ¸¬è©¦ API
curl http://localhost:8000/health
# é æœŸå›æ‡‰: {"status":"healthy"}

# æ¸¬è©¦ Swagger æ–‡æª”
# é–‹å•Ÿç€è¦½å™¨: http://your-server-ip:8000/api/docs
```

---

## 4. è³‡æ–™åº«å‚™ä»½èˆ‡æ¢å¾©

### è‡ªå‹•å‚™ä»½è…³æœ¬

```bash
#!/bin/bash
# scripts/backup_db.sh

BACKUP_DIR="/opt/backups/postgres"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="$BACKUP_DIR/rag_db_$TIMESTAMP.sql.gz"

# å»ºç«‹å‚™ä»½ç›®éŒ„
mkdir -p $BACKUP_DIR

# åŸ·è¡Œå‚™ä»½
docker exec rag_postgres pg_dump -U postgres rag_db | gzip > $BACKUP_FILE

# ä¿ç•™æœ€è¿‘ 30 å¤©çš„å‚™ä»½
find $BACKUP_DIR -name "*.sql.gz" -mtime +30 -delete

echo "Backup completed: $BACKUP_FILE"
```

### è¨­å®š Cron å®šæ™‚å‚™ä»½

```bash
# æ¯å¤©å‡Œæ™¨ 2 é»åŸ·è¡Œå‚™ä»½
sudo crontab -e

# åŠ å…¥ä»¥ä¸‹è¡Œ
0 2 * * * /opt/rag_web_backend/scripts/backup_db.sh >> /var/log/backup.log 2>&1
```

### æ¢å¾©è³‡æ–™åº«

```bash
# å¾å‚™ä»½æ¢å¾©
gunzip -c /opt/backups/postgres/rag_db_20251031_020000.sql.gz | \
  docker exec -i rag_postgres psql -U postgres -d rag_db
```

---

## 5. ç›£æ§èˆ‡æ—¥èªŒ

### æ‡‰ç”¨ç›£æ§

```bash
# æŸ¥çœ‹å®¹å™¨è³‡æºä½¿ç”¨
docker stats

# æŸ¥çœ‹å¾Œç«¯æ—¥èªŒ
docker logs -f rag_backend --tail 100

# æŸ¥çœ‹ Celery Worker æ—¥èªŒ
docker logs -f rag_celery_worker --tail 100

# æŸ¥çœ‹ Nginx è¨ªå•æ—¥èªŒ
docker exec rag_nginx tail -f /var/log/nginx/access.log
```

### Flower ç›£æ§é¢æ¿

è¨ªå• `http://your-server-ip:5555` æŸ¥çœ‹ Celery ä»»å‹™ç‹€æ…‹

---

## 6. æ›´æ–°éƒ¨ç½²

```bash
# 1. æ‹‰å–æœ€æ–°ç¨‹å¼ç¢¼
cd /opt/rag_web_backend
sudo git pull origin master

# 2. é‡æ–°å»ºæ§‹ä¸¦å•Ÿå‹•
sudo docker-compose --env-file .env.production up -d --build

# 3. åŸ·è¡Œè³‡æ–™åº«é·ç§»
sudo docker-compose exec backend alembic upgrade head

# 4. é‡å•Ÿæœå‹™
sudo docker-compose restart backend celery_worker
```

---

## 7. æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

1. **è³‡æ–™åº«é€£ç·šå¤±æ•—**
```bash
# æª¢æŸ¥ PostgreSQL æ˜¯å¦æ­£å¸¸é‹è¡Œ
docker logs rag_postgres

# é‡å•Ÿè³‡æ–™åº«
docker-compose restart postgres
```

2. **Redis é€£ç·šå¤±æ•—**
```bash
# æ¸¬è©¦ Redis é€£ç·š
docker exec rag_redis redis-cli -a your-redis-password ping

# æ‡‰å›å‚³: PONG
```

3. **Celery ä»»å‹™å¡ä½**
```bash
# é‡å•Ÿ Worker
docker-compose restart celery_worker

# æ¸…ç©ºä»»å‹™ä½‡åˆ—
docker exec rag_redis redis-cli -a your-redis-password FLUSHDB
```

---

## 8. å®‰å…¨æª¢æŸ¥æ¸…å–®

- âœ… ä¿®æ”¹æ‰€æœ‰é è¨­å¯†ç¢¼
- âœ… ä½¿ç”¨å¼·åŠ å¯†é‡‘é‘°ï¼ˆSECRET_KEY, JWT_SECRET_KEYï¼‰
- âœ… å•Ÿç”¨ HTTPSï¼ˆç”Ÿç”¢ç’°å¢ƒï¼‰
- âœ… é…ç½®é˜²ç«ç‰†è¦å‰‡
- âœ… å®šæœŸæ›´æ–°ç³»çµ±å’Œ Docker æ˜ åƒ
- âœ… è¨­å®šè‡ªå‹•å‚™ä»½
- âœ… é™åˆ¶ API é€Ÿç‡
- âœ… é…ç½®æ—¥èªŒè¼ªè½‰
- âœ… ä½¿ç”¨ç’°å¢ƒè®Šæ•¸ç®¡ç†æ•æ„Ÿè³‡è¨Š
- âœ… å•Ÿç”¨å®¹å™¨å¥åº·æª¢æŸ¥

---

**ä¸‹ä¸€æ­¥**: é–±è®€ [08_DEVELOPMENT_GUIDE.md](./08_DEVELOPMENT_GUIDE.md) äº†è§£é–‹ç™¼æŒ‡å—
