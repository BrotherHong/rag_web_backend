"""ä¸Šå‚³ç®¡ç† API è·¯ç”± - è™•ç†æ‰¹æ¬¡ä¸Šå‚³å’Œé€²åº¦è¿½è¹¤"""

from typing import List, Dict, Optional
from datetime import datetime
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form, status, BackgroundTasks
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from pydantic import BaseModel

from app.core.database import get_db
from app.core.security import get_current_user
from app.models import User

router = APIRouter(prefix="/upload", tags=["ä¸Šå‚³ç®¡ç†"])

# æ¨¡æ“¬çš„ä¸Šå‚³ä»»å‹™å„²å­˜ï¼ˆå¯¦éš›æ‡‰ç”¨ä¸­æ‡‰è©²ä½¿ç”¨ Redis æˆ–è³‡æ–™åº«ï¼‰
upload_tasks: Dict[str, dict] = {}


# Pydantic Models
class CheckDuplicatesRequest(BaseModel):
    """æª¢æŸ¥é‡è¤‡æª”æ¡ˆçš„è«‹æ±‚æ¨¡å‹"""
    filenames: List[str]


@router.post("/batch", summary="æ‰¹æ¬¡ä¸Šå‚³æª”æ¡ˆ")
async def batch_upload(
    background_tasks: BackgroundTasks,
    files: List[UploadFile] = File(...),
    categories: str = Form("{}"),  # JSON å­—ä¸²æ ¼å¼çš„åˆ†é¡å°æ‡‰
    removeFileIds: str = Form("[]"),  # è¦åˆªé™¤çš„èˆŠæª”æ¡ˆ ID åˆ—è¡¨
    startProcessing: str = Form("false"),  # æ˜¯å¦ç«‹å³é–‹å§‹è™•ç†
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    æ‰¹æ¬¡ä¸Šå‚³å¤šå€‹æª”æ¡ˆ
    
    å‰ç«¯ç™¼é€æ ¼å¼:
    - files: æª”æ¡ˆåˆ—è¡¨
    - categories: JSON å­—ä¸² {"filename1.pdf": "åˆ†é¡åç¨±1", ...}
    - removeFileIds: JSON å­—ä¸² [1, 2, 3, ...]
    
    è¿”å›æ ¼å¼:
    {
      success: true,
      taskId: "uuid",
      message: "ä¸Šå‚³ä»»å‹™å·²å»ºç«‹"
    }
    """
    import uuid
    import json
    import os
    from app.models import File as FileModel, Category
    from app.services.file_storage import file_storage
    from app.services.activity import activity_service
    
    # Debug: è¼¸å‡ºæ¥æ”¶åˆ°çš„åƒæ•¸
    print(f"\n{'='*60}")
    print(f"ğŸ“¤ æ”¶åˆ°ä¸Šå‚³è«‹æ±‚")
    print(f"æª”æ¡ˆæ•¸é‡: {len(files)}")
    print(f"startProcessing åƒæ•¸: {startProcessing}")
    print(f"{'='*60}\n")
    
    # è§£æåƒæ•¸
    try:
        category_map = json.loads(categories)
        remove_ids = json.loads(removeFileIds)
    except:
        category_map = {}
        remove_ids = []
    
    # ç”Ÿæˆä»»å‹™ ID
    task_id = str(uuid.uuid4())
    
    # 1. å…ˆåˆªé™¤è¦ç§»é™¤çš„èˆŠæª”æ¡ˆ
    if remove_ids:
        for file_id in remove_ids:
            try:
                old_file = await db.get(FileModel, file_id)
                if old_file and old_file.department_id == current_user.department_id:
                    # åˆªé™¤å¯¦é«”æª”æ¡ˆ
                    if os.path.exists(old_file.file_path):
                        os.remove(old_file.file_path)
                    # åˆªé™¤è³‡æ–™åº«è¨˜éŒ„
                    await db.delete(old_file)
            except Exception as e:
                print(f"åˆªé™¤æª”æ¡ˆ {file_id} å¤±æ•—: {str(e)}")
        
        await db.commit()
    
    # 2. åˆå§‹åŒ–ä»»å‹™è¨˜éŒ„ï¼ˆç”¨æ–¼å‰ç«¯è¼ªè©¢ï¼‰
    file_list = []
    for file in files:
        file_list.append({
            "name": file.filename,
            "status": "pending",
            "progress": 0,
            "error": None
        })
    
    task = {
        "task_id": task_id,
        "user_id": current_user.id,
        "status": "processing",
        "totalFiles": len(files),
        "processedFiles": 0,
        "successFiles": 0,
        "failedFiles": 0,
        "deletedFiles": len(remove_ids),
        "files": file_list,
        "created_at": datetime.now().isoformat(),
        "updated_at": datetime.now().isoformat()
    }
    upload_tasks[task_id] = task
    
    # 3. è™•ç†æ–°æª”æ¡ˆä¸Šå‚³
    success_count = 0
    
    for idx, file in enumerate(files):
        # æ›´æ–°ç•¶å‰æª”æ¡ˆç‹€æ…‹ç‚ºè™•ç†ä¸­
        task["files"][idx]["status"] = "processing"
        task["files"][idx]["progress"] = 50
        task["updated_at"] = datetime.now().isoformat()
        
        try:
            # é©—è­‰æª”æ¡ˆ
            is_valid, error_msg = await file_storage.validate_file(file, db)
            if not is_valid:
                task["files"][idx]["status"] = "failed"
                task["files"][idx]["error"] = error_msg
                task["failedFiles"] += 1
                continue
            
            # å–å¾—åˆ†é¡
            category_name = category_map.get(file.filename)
            category_id = None
            if category_name:
                category_query = select(Category).where(
                    Category.name == category_name,
                    Category.department_id == current_user.department_id
                )
                category_result = await db.execute(category_query)
                category = category_result.scalar_one_or_none()
                if category:
                    category_id = category.id
            
            # å„²å­˜æª”æ¡ˆ
            unique_filename, file_path, file_size = await file_storage.save_upload_file(
                file,
                current_user.department_id
            )
            
            # å»ºç«‹è³‡æ–™åº«è¨˜éŒ„
            ext = os.path.splitext(file.filename)[1].lower()
            db_file = FileModel(
                filename=unique_filename,
                original_filename=file.filename,
                file_path=file_path,
                file_size=file_size,
                file_type=ext[1:] if ext else "unknown",
                mime_type=file.content_type,
                category_id=category_id,
                department_id=current_user.department_id,
                uploader_id=current_user.id,
                status="completed"  # ä½¿ç”¨ FileStatus.COMPLETED
            )
            
            db.add(db_file)
            await db.flush()
            
            # æ›´æ–°æª”æ¡ˆç‹€æ…‹ç‚ºå®Œæˆ
            task["files"][idx]["status"] = "completed"
            task["files"][idx]["progress"] = 100
            task["successFiles"] += 1
            success_count += 1
            
        except Exception as e:
            task["files"][idx]["status"] = "failed"
            task["files"][idx]["error"] = str(e)
            task["failedFiles"] += 1
        
        # æ›´æ–°å·²è™•ç†æª”æ¡ˆæ•¸
        task["processedFiles"] = idx + 1
        task["updated_at"] = datetime.now().isoformat()
    
    await db.commit()
    
    # è¨˜éŒ„æ´»å‹•ï¼ˆåŒ…å«æª”æ¡ˆåç¨±åˆ—è¡¨ï¼‰
    if success_count > 0:
        # æ”¶é›†æˆåŠŸä¸Šå‚³çš„æª”æ¡ˆåç¨±
        success_files = [f["name"] for f in task["files"] if f["status"] == "completed"]
        file_list_str = "ã€".join(success_files[:5])  # æœ€å¤šé¡¯ç¤º 5 å€‹æª”æ¡ˆå
        if len(success_files) > 5:
            file_list_str += f" ç­‰ {len(success_files)} å€‹æª”æ¡ˆ"
        
        await activity_service.log_activity(
            db=db,
            user_id=current_user.id,
            activity_type="UPLOAD",
            description=f"æ‰¹æ¬¡ä¸Šå‚³æª”æ¡ˆ: {file_list_str}",
            department_id=current_user.department_id
        )
        await db.commit()  # æäº¤æ´»å‹•è¨˜éŒ„
    
    # æ›´æ–°ä»»å‹™æœ€çµ‚ç‹€æ…‹
    task["status"] = "completed" if task["failedFiles"] == 0 else "partial"
    task["updated_at"] = datetime.now().isoformat()
    
    # å¦‚æœéœ€è¦é–‹å§‹è™•ç†ï¼Œè§¸ç™¼èƒŒæ™¯ä»»å‹™
    should_process = startProcessing.lower() == "true"
    
    print(f"\n{'='*60}")
    print(f"ğŸ” æª¢æŸ¥æ˜¯å¦éœ€è¦è§¸ç™¼è™•ç†")
    print(f"startProcessing: '{startProcessing}'")
    print(f"should_process: {should_process}")
    print(f"success_count: {success_count}")
    print(f"{'='*60}\n")
    
    if should_process and success_count > 0:
        # æ”¶é›†æˆåŠŸä¸Šå‚³çš„æª”æ¡ˆ ID
        uploaded_file_ids = []
        for idx, file in enumerate(files):
            if task["files"][idx]["status"] == "completed":
                # å¾è³‡æ–™åº«æŸ¥è©¢æª”æ¡ˆ ID
                result = await db.execute(
                    select(FileModel).where(
                        FileModel.original_filename == file.filename,
                        FileModel.department_id == current_user.department_id
                    ).order_by(FileModel.id.desc()).limit(1)
                )
                file_record = result.scalar_one_or_none()
                if file_record:
                    uploaded_file_ids.append(file_record.id)
        
        if uploaded_file_ids and background_tasks:
            # å•Ÿå‹•èƒŒæ™¯è™•ç†ä»»å‹™
            from app.services.file_processor import file_processing_service
            
            print(f"ğŸš€ å•Ÿå‹•èƒŒæ™¯è™•ç†ä»»å‹™ï¼Œæª”æ¡ˆ IDs: {uploaded_file_ids}")
            
            background_tasks.add_task(
                process_files_in_background,
                uploaded_file_ids,
                task_id
            )
            task["status"] = "processing"
            task["message"] = "æª”æ¡ˆä¸Šå‚³å®Œæˆï¼Œé–‹å§‹è™•ç†ä¸­..."
    
    return {
        "success": True,
        "taskId": task_id,
        "message": f"æˆåŠŸä¸Šå‚³ {success_count} å€‹æª”æ¡ˆ" + (" (è™•ç†ä¸­...)" if should_process and success_count > 0 else "")
    }


async def process_files_in_background(file_ids: List[int], task_id: str):
    """èƒŒæ™¯ä»»å‹™ï¼šè™•ç†æª”æ¡ˆ"""
    from app.services.file_processor import file_processing_service
    from app.core.database import AsyncSessionLocal
    
    print(f"\n{'='*60}")
    print(f"ğŸ”„ èƒŒæ™¯è™•ç†é–‹å§‹")
    print(f"ä»»å‹™ ID: {task_id}")
    print(f"æª”æ¡ˆ IDs: {file_ids}")
    print(f"{'='*60}\n")
    
    # å»ºç«‹æ–°çš„ DB session
    async with AsyncSessionLocal() as session:
        try:
            results = await file_processing_service.process_files_batch(
                file_ids=file_ids,
                task_id=task_id,
                db=session
            )
            
            print(f"\n{'='*60}")
            print(f"âœ… èƒŒæ™¯è™•ç†å®Œæˆ")
            print(f"æˆåŠŸ: {results['success']}, å¤±æ•—: {results['failed']}")
            print(f"{'='*60}\n")
            
            # æ›´æ–°ä»»å‹™ç‹€æ…‹
            if task_id in upload_tasks:
                task = upload_tasks[task_id]
                task["processing_results"] = results
                task["status"] = "completed" if results["failed"] == 0 else "partial"
                task["updated_at"] = datetime.now().isoformat()
                
        except Exception as e:
            print(f"\n{'='*60}")
            print(f"âŒ èƒŒæ™¯è™•ç†å¤±æ•—: {e}")
            print(f"{'='*60}\n")
            
            import traceback
            traceback.print_exc()
            
            if task_id in upload_tasks:
                task = upload_tasks[task_id]
                task["status"] = "failed"
                task["error"] = str(e)
                task["updated_at"] = datetime.now().isoformat()


@router.get("/progress/{task_id}", summary="æŸ¥è©¢ä¸Šå‚³é€²åº¦")
async def get_upload_progress(
    task_id: str,
    current_user: User = Depends(get_current_user)
):
    """
    æŸ¥è©¢æ‰¹æ¬¡ä¸Šå‚³çš„é€²åº¦
    
    è¿”å›æ ¼å¼:
    {
      task_id: string,
      status: "processing" | "completed" | "failed" | "partial",
      total_files: number,
      completed_files: number,
      failed_files: number,
      progress: number (0-100),
      results: [{filename, success, error}]
    }
    """
    # æŸ¥æ‰¾ä»»å‹™
    task = upload_tasks.get(task_id)
    
    if not task:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ä¸Šå‚³ä»»å‹™ä¸å­˜åœ¨"
        )
    
    # æ¬Šé™æª¢æŸ¥
    if task["user_id"] != current_user.id:
        from app.models.user import UserRole
        if current_user.role != UserRole.SUPER_ADMIN:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="ç„¡æ¬Šé™æŸ¥çœ‹æ­¤ä»»å‹™"
            )
    
    # è¿”å›æ ¼å¼åŒ¹é…å‰ç«¯æœŸå¾…
    return {
        "success": True,
        "data": {
            "taskId": task_id,
            "status": task["status"],
            "totalFiles": task["totalFiles"],
            "processedFiles": task["processedFiles"],
            "successFiles": task["successFiles"],
            "failedFiles": task["failedFiles"],
            "deletedFiles": task.get("deletedFiles", 0),
            "files": task["files"],
            "updatedAt": task["updated_at"]
        }
    }


@router.get("/tasks", summary="å–å¾—ä½¿ç”¨è€…çš„ä¸Šå‚³ä»»å‹™åˆ—è¡¨")
async def get_user_upload_tasks(
    current_user: User = Depends(get_current_user)
):
    """
    å–å¾—ç•¶å‰ä½¿ç”¨è€…çš„æ‰€æœ‰ä¸Šå‚³ä»»å‹™
    
    å‰ç«¯æœŸæœ›æ ¼å¼:
    {
      items: [{
        task_id: string,
        total_files: number,
        completed_files: number,
        status: string,
        created_at: string
      }]
    }
    """
    # ç¯©é¸ä½¿ç”¨è€…çš„ä»»å‹™
    user_tasks = [
        {
            "task_id": task_id,
            "total_files": task["total_files"],
            "completed_files": task["completed_files"],
            "failed_files": task["failed_files"],
            "status": task["status"],
            "created_at": task["created_at"],
            "updated_at": task["updated_at"]
        }
        for task_id, task in upload_tasks.items()
        if task["user_id"] == current_user.id
    ]
    
    # æŒ‰å»ºç«‹æ™‚é–“æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    user_tasks.sort(key=lambda x: x["created_at"], reverse=True)
    
    return {
        "success": True,
        "items": user_tasks,
        "total": len(user_tasks)
    }


@router.delete("/tasks/{task_id}", summary="åˆªé™¤ä¸Šå‚³ä»»å‹™")
async def delete_upload_task(
    task_id: str,
    current_user: User = Depends(get_current_user)
):
    """
    åˆªé™¤æŒ‡å®šçš„ä¸Šå‚³ä»»å‹™è¨˜éŒ„
    
    åªèƒ½åˆªé™¤å·²å®Œæˆæˆ–å¤±æ•—çš„ä»»å‹™
    """
    # æŸ¥æ‰¾ä»»å‹™
    task = upload_tasks.get(task_id)
    
    if not task:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ä¸Šå‚³ä»»å‹™ä¸å­˜åœ¨"
        )
    
    # æ¬Šé™æª¢æŸ¥
    if task["user_id"] != current_user.id and current_user.role.value != "ADMIN":
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="ç„¡æ¬Šé™åˆªé™¤æ­¤ä»»å‹™"
        )
    
    # æª¢æŸ¥ä»»å‹™ç‹€æ…‹
    if task["status"] == "processing":
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="ç„¡æ³•åˆªé™¤è™•ç†ä¸­çš„ä»»å‹™"
        )
    
    # åˆªé™¤ä»»å‹™
    del upload_tasks[task_id]
    
    return {
        "success": True,
        "message": "ä¸Šå‚³ä»»å‹™å·²åˆªé™¤"
    }


@router.post("/check-duplicates", summary="æª¢æŸ¥æª”æ¡ˆé‡è¤‡")
async def check_duplicates(
    request: CheckDuplicatesRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨ä¸¦æ‰¾å‡ºç›¸é—œæª”æ¡ˆ
    
    å‰ç«¯æœŸæœ›æ ¼å¼:
    Request: { filenames: ["file1.pdf", "file2.docx"] }
    Response: {
      results: [
        {
          fileName: "file1.pdf",
          isDuplicate: true,
          duplicateFile: { id, name, size, uploadDate, category },
          relatedFiles: [],
          suggestReplace: true
        },
        {
          fileName: "file2.docx",
          isDuplicate: false,
          duplicateFile: null,
          relatedFiles: [{ id, name, size, uploadDate, category }],
          suggestReplace: false
        }
      ]
    }
    """
    from app.models import File as FileModel
    from sqlalchemy.orm import joinedload
    
    results = []
    
    for filename in request.filenames:
        # æª¢æŸ¥å®Œå…¨é‡è¤‡çš„æª”æ¡ˆ
        exact_match_query = select(FileModel).options(
            joinedload(FileModel.category)
        ).where(
            FileModel.department_id == current_user.department_id,
            FileModel.original_filename == filename
        )
        exact_match_result = await db.execute(exact_match_query)
        exact_match = exact_match_result.scalar_one_or_none()
        
        # æŸ¥æ‰¾ç›¸é—œæª”æ¡ˆï¼ˆæª”åç›¸ä¼¼ä½†ä¸å®Œå…¨ç›¸åŒï¼‰
        base_name = filename.rsplit('.', 1)[0]  # å»æ‰å‰¯æª”å
        related_query = select(FileModel).options(
            joinedload(FileModel.category)
        ).where(
            FileModel.department_id == current_user.department_id,
            FileModel.original_filename.like(f"%{base_name}%"),
            FileModel.original_filename != filename
        ).limit(5)
        related_result = await db.execute(related_query)
        related_files = related_result.scalars().all()
        
        # æ§‹å»ºå›æ‡‰
        file_result = {
            "fileName": filename,
            "isDuplicate": exact_match is not None,
            "duplicateFile": None,
            "relatedFiles": [],
            "suggestReplace": exact_match is not None
        }
        
        if exact_match:
            file_result["duplicateFile"] = {
                "id": exact_match.id,
                "name": exact_match.original_filename,
                "size": f"{exact_match.file_size / 1024:.1f} KB" if exact_match.file_size else "æœªçŸ¥",
                "uploadDate": exact_match.created_at.strftime("%Y-%m-%d %H:%M"),
                "category": exact_match.category.name if exact_match.category else "æœªåˆ†é¡"
            }
        
        for related_file in related_files:
            file_result["relatedFiles"].append({
                "id": related_file.id,
                "name": related_file.original_filename,
                "size": f"{related_file.file_size / 1024:.1f} KB" if related_file.file_size else "æœªçŸ¥",
                "uploadDate": related_file.created_at.strftime("%Y-%m-%d %H:%M"),
                "category": related_file.category.name if related_file.category else "æœªåˆ†é¡"
            })
        
        results.append(file_result)
    
    return {
        "success": True,
        "results": results
    }
