"""
æ–‡æª”æ‘˜è¦è™•ç†å™¨ - åŸºæ–¼main/utils/summarizer.pyçš„é‚è¼¯
"""

import json
from pathlib import Path
from typing import Dict, Optional, List, Tuple
from app.services.llm.ollama_client import OllamaClient
from app.services.llm.prompts import (
    RAG_DOCUMENT_SUMMARY,
    DOCUMENT_CLASSIFICATION,
    FORM_DOCUMENT_SUMMARY
)


class SummaryProcessor:
    """
    è™•ç†æ–‡æª”ä»¥ç”Ÿæˆæ‘˜è¦ - èˆ‡mainç‰ˆæœ¬ä¿æŒä¸€è‡´
    """
    
    def __init__(self, ollama_client: Optional[OllamaClient] = None):
        """
        åˆå§‹åŒ–æ‘˜è¦è™•ç†å™¨
        
        åƒæ•¸:
            ollama_client: OllamaClient å¯¦ä¾‹
        """
        self.client = ollama_client or OllamaClient()
    
    def process_markdown_file(
        self,
        md_file_path: Path,
        output_json_path: Path
    ) -> bool:
        """
        è™•ç†å–®ä¸€ markdown æª”æ¡ˆç”Ÿæˆæ‘˜è¦
        
        åƒæ•¸:
            md_file_path: Markdown æª”æ¡ˆè·¯å¾‘
            output_json_path: è¼¸å‡º JSON è·¯å¾‘
            
        è¿”å›:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # è®€å–æª”æ¡ˆå…§å®¹
            with open(md_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if not content.strip():
                print(f"âš ï¸ æª”æ¡ˆå…§å®¹ç‚ºç©º: {md_file_path.name}")
                return False
            
            filename = md_file_path.name
            file_path = str(md_file_path)
            
            # ç”Ÿæˆæ‘˜è¦ (ä½¿ç”¨èˆ‡mainä¸€è‡´çš„é‚è¼¯)
            summary, doc_type, chunk_content = self._generate_summary(
                content, filename, file_path, output_json_path.parent
            )
            
            if not summary or summary.startswith('éŒ¯èª¤:'):
                print(f"âŒ æ‘˜è¦ç”Ÿæˆå¤±æ•—: {summary}")
                return False
            
            # å»ºç«‹ä¸»æ‘˜è¦è³‡æ–™
            summary_data = {
                'filename': filename,
                'summary': summary,
                'summary_length': len(summary),
                'doc_type': doc_type,
                'original_content': chunk_content
            }
            
            # å„²å­˜ç‚º JSON
            output_json_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_json_path, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æ‘˜è¦ç”ŸæˆæˆåŠŸ ({len(summary)} å­—)")
            return True
            
        except Exception as e:
            print(f"âŒ è™•ç†å¤±æ•—: {e}")
            return False
    
    def _generate_summary(
        self, 
        content: str, 
        filename: str = "", 
        file_path: str = "",
        output_dir: Path = None
    ) -> Tuple[str, str, str]:
        """
        ä½¿ç”¨ Ollama ç”Ÿæˆæ‘˜è¦ - èˆ‡mainç‰ˆæœ¬å®Œå…¨ä¸€è‡´
        
        åƒæ•¸:
            content: æ–‡æª”å…§å®¹
            filename: æ–‡æª”æ–‡ä»¶å
            file_path: æ–‡æª”å®Œæ•´è·¯å¾‘
            output_dir: è¼¸å‡ºç›®éŒ„ï¼ˆç”¨æ–¼ä¿å­˜åˆ†å¡Šæ‘˜è¦ï¼‰
            
        è¿”å›:
            (ç”Ÿæˆçš„æ‘˜è¦, æ–‡æª”é¡å‹, chunkå…§å®¹) tuple
        """
        # å…ˆåˆ¤æ–·æ–‡æª”é¡å‹
        doc_type = self._classify_document(content)
        print(f"  æ–‡æª”åˆ†é¡: {doc_type}")
        
        if doc_type == "Form Mode":
            # è¡¨å–®é¡æ–‡æª”
            if len(content) > 1500:
                # é•·è¡¨å–®ï¼šä½¿ç”¨åˆ†å¡Šè™•ç†
                return self._generate_chunked_summary(
                    content, filename, file_path, output_dir, doc_type="Form Mode"
                )
            else:
                # çŸ­è¡¨å–®ï¼šç›´æ¥ç”Ÿæˆç°¡åŒ–æ‘˜è¦
                prompt = FORM_DOCUMENT_SUMMARY.format(text=content, filename=filename)
                response = self.client.generate(prompt)
                summary = self._extract_final_summary(response)

                # æ”¾å¯¬å­—æ•¸é™åˆ¶è‡³ 400 å­—
                if len(summary) > 400:
                    print(f"  è­¦å‘Š: Form Mode æ‘˜è¦è¼ƒé•· ({len(summary)}å­—)")
                
                return (summary, doc_type, content)
        else:
            # è³‡è¨Šé¡æ–‡æª”ä½¿ç”¨è©³ç´°æ‘˜è¦
            if len(content) > 1500:
                # è¿”å› (æ‘˜è¦, é¡å‹, ç¬¬ä¸€å¡Šå…§å®¹)
                return self._generate_chunked_summary(
                    content, filename, file_path, output_dir, doc_type="Info Mode"
                )
            else:
                prompt = RAG_DOCUMENT_SUMMARY.format(filename=filename, text=content)
                response = self.client.generate(prompt)
                summary = self._extract_final_summary(response)
                return (summary, doc_type, content)
    
    def _classify_document(self, content: str) -> str:
        """
        åˆ†é¡æ–‡æª”é¡å‹
        
        åƒæ•¸:
            content: æ–‡æª”å…§å®¹
            
        è¿”å›:
            "Form Mode" æˆ– "Info Mode"
        """
        # å–å‰2000å­—é€²è¡Œåˆ†é¡åˆ¤æ–·
        classification_content = content[:2000]
        prompt = DOCUMENT_CLASSIFICATION.format(text=classification_content)
        response = self.client.generate(prompt).strip()
        
        # æ¸…ç†æ€è€ƒæ¨™ç±¤ï¼Œåªå–æœ€çµ‚ç­”æ¡ˆ
        clean_response = self._extract_final_summary(response)
        print(f"  åˆ†é¡å›æ‡‰: {clean_response}")
        
        # ç¢ºä¿å›æ‡‰æ ¼å¼æ­£ç¢º
        if "Form Mode" in clean_response:
            return "Form Mode"
        elif "Info Mode" in clean_response:
            return "Info Mode"
        else:
            # é»˜èªç‚ºè³‡è¨Šæ¨¡å¼
            print(f"âš ï¸ ç„¡æ³•ç¢ºå®šæ–‡æª”é¡å‹ï¼Œé è¨­ç‚º Info Mode")
            return "Info Mode"
    
    def _generate_chunked_summary(
        self, 
        content: str, 
        filename: str, 
        file_path: str, 
        output_dir: Path,
        doc_type: str = "Info Mode"
    ) -> Tuple[str, str, str]:
        """
        ç‚ºé•·æ–‡æª”ç”Ÿæˆåˆ†å¡Šæ‘˜è¦ - èˆ‡mainç‰ˆæœ¬å®Œå…¨ä¸€è‡´
        
        åƒæ•¸:
            content: æ–‡æª”å…§å®¹
            filename: æ–‡æª”æ–‡ä»¶å
            file_path: æ–‡æª”å®Œæ•´è·¯å¾‘
            output_dir: è¼¸å‡ºç›®éŒ„
            doc_type: æ–‡æª”é¡å‹ï¼ˆ"Info Mode" æˆ– "Form Mode"ï¼‰
            
        è¿”å›:
            (ç¸½é«”æ‘˜è¦æˆ–ç¬¬ä¸€å¡Šæ‘˜è¦, æ–‡æª”é¡å‹, ç¬¬ä¸€å¡Šå…§å®¹) tuple
        """
        print(f"  æ–‡æª”é•·åº¦è¶…é1500å­—ï¼Œé–‹å§‹åˆ†å¡Šè™•ç†...")
        
        # ä½¿ç”¨èˆ‡mainä¸€è‡´çš„åˆ†å¡Šåƒæ•¸
        chunks = self._split_content(content, chunk_size=950, overlap=150)
        print(f"  åˆ†ç‚º {len(chunks)} å€‹å¡Š (chunk_size=950, overlap=150)")
        
        # æ ¹æ“šæ–‡æª”é¡å‹é¸æ“‡ prompt
        if doc_type == "Form Mode":
            prompt_template = FORM_DOCUMENT_SUMMARY
        else:
            prompt_template = RAG_DOCUMENT_SUMMARY
        
        summaries = []
        for i, chunk in enumerate(chunks, 1):
            print(f"  è™•ç†ç¬¬ {i}/{len(chunks)} å¡Š...")
            
            if doc_type == "Form Mode":
                prompt = prompt_template.format(text=chunk, filename=filename)
            else:
                prompt = prompt_template.format(filename=filename, text=chunk)
            
            response = self.client.generate(prompt)
            chunk_summary = self._extract_final_summary(response)
            summaries.append(chunk_summary)
            
            # ä¿å­˜æ¯å€‹å¡Šçš„æ‘˜è¦ç‚ºç¨ç«‹æ–‡ä»¶ (å¾ç¬¬2å¡Šé–‹å§‹)
            if i > 1 and output_dir:
                chunk_filename = filename.replace('.md', f'_part{i}.md')
                chunk_summary_file = output_dir / f"{Path(filename).stem}_part{i}_summary.json"
                
                chunk_summary_data = {
                    'filename': chunk_filename,
                    'summary': chunk_summary,
                    'summary_length': len(chunk_summary),
                    'doc_type': doc_type,
                    'chunk_info': f"ç¬¬ {i} å¡Šï¼Œå…± {len(chunks)} å¡Š",
                    'original_content': chunk
                }
                
                try:
                    with open(chunk_summary_file, 'w', encoding='utf-8') as f:
                        json.dump(chunk_summary_data, f, ensure_ascii=False, indent=2)
                    print(f"  âœ… å·²ä¿å­˜ç¬¬ {i} å¡Šæ‘˜è¦: {chunk_summary_file.name}")
                except Exception as e:
                    print(f"  âš ï¸ ä¿å­˜ç¬¬ {i} å¡Šæ‘˜è¦å¤±æ•—: {e}")
        
        # åœ¨ç¬¬ä¸€å¡Šæ‘˜è¦ä¸­æ·»åŠ åˆ†å¡Šä¿¡æ¯
        first_summary_with_info = summaries[0]
        if len(chunks) > 1:
            print(f"  ğŸ“„ é•·æ–‡æª”åˆ†ç‚º {len(chunks)} å€‹å¡Šï¼Œå·²ç”Ÿæˆæ‰€æœ‰åˆ†å¡Šæ‘˜è¦")
        
        # è¿”å›ç¬¬ä¸€å¡Šçš„æ‘˜è¦ã€æ–‡æª”é¡å‹å’Œç¬¬ä¸€å¡Šå…§å®¹
        return (first_summary_with_info, doc_type, chunks[0])
    
    def _split_content(self, content: str, chunk_size: int = 950, overlap: int = 150) -> List[str]:
        """
        å°‡å…§å®¹åˆ†å¡Šï¼Œä¿æŒé‡ç–Š - èˆ‡mainç‰ˆæœ¬å®Œå…¨ä¸€è‡´
        
        åƒæ•¸:
            content: è¦åˆ†å¡Šçš„å…§å®¹
            chunk_size: æ¯å¡Šå¤§å° (é»˜èª950ï¼Œèˆ‡mainä¸€è‡´)
            overlap: é‡ç–Šå­—æ•¸ (é»˜èª150ï¼Œèˆ‡mainä¸€è‡´)
            
        è¿”å›:
            åˆ†å¡Šå¾Œçš„å…§å®¹åˆ—è¡¨
        """
        if len(content) <= chunk_size:
            return [content]
        
        chunks = []
        start = 0
        
        while start < len(content):
            end = start + chunk_size
            
            if end >= len(content):
                # æœ€å¾Œä¸€å¡Š
                chunks.append(content[start:])
                break
            
            # å°‹æ‰¾é©ç•¶çš„åˆ†å‰²é»ï¼ˆå„ªå…ˆåœ¨æ®µè½æˆ–å¥å­çµå°¾ï¼‰
            chunk_text = content[start:end]
            
            # å‘å‰å°‹æ‰¾æ®µè½åˆ†å‰²é»
            last_paragraph = chunk_text.rfind('\n\n')
            last_sentence = chunk_text.rfind('ã€‚')
            
            if last_paragraph > chunk_size - 200:  # å¦‚æœæ®µè½åˆ†å‰²é»ä¸å¤ªé 
                actual_end = start + last_paragraph + 2
            elif last_sentence > chunk_size - 100:  # å¦‚æœå¥å­åˆ†å‰²é»ä¸å¤ªé 
                actual_end = start + last_sentence + 1
            else:
                actual_end = end
            
            chunks.append(content[start:actual_end])
            start = actual_end - overlap  # ä¿æŒé‡ç–Š
        
        return chunks
    
    def _extract_final_summary(self, response: str) -> str:
        """
        å¾å›æ‡‰ä¸­æå–æœ€çµ‚æ‘˜è¦ï¼Œè‹¥å­˜åœ¨å‰‡ç§»é™¤æ€è€ƒæ¨™ç±¤ - èˆ‡mainç‰ˆæœ¬å®Œå…¨ä¸€è‡´
        
        åƒæ•¸:
            response: æ¨¡å‹çš„åŸå§‹å›æ‡‰
            
        è¿”å›:
            ä¹¾æ·¨çš„æ‘˜è¦å…§å®¹
        """
        if not response:
            return response
        
        # æª¢æŸ¥å›æ‡‰æ˜¯å¦åŒ…å«æ€è€ƒæ¨™ç±¤
        if '</think>' in response:
            # æ‰¾åˆ°æœ€å¾Œä¸€å€‹æ€è€ƒæ¨™ç±¤çš„çµå°¾
            think_end = response.rfind('</think>')
            if think_end != -1:
                # æå–æ€è€ƒæ¨™ç±¤å¾Œçš„å…§å®¹
                summary = response[think_end + 8:].strip()
                return summary if summary else response
        
        return response
    
    def _classify_document(self, content: str) -> str:
        """
        åˆ†é¡æ–‡æª”é¡å‹
        
        åƒæ•¸:
            content: æ–‡æª”å…§å®¹
            
        è¿”å›:
            "Form Mode" æˆ– "Info Mode"
        """
        # å–å‰2000å­—é€²è¡Œåˆ†é¡åˆ¤æ–·
        classification_content = content[:2000]
        prompt = DOCUMENT_CLASSIFICATION.format(text=classification_content)
        response = self.client.generate(prompt).strip()
        
        # æ¸…ç†æ€è€ƒæ¨™ç±¤ï¼Œåªå–æœ€çµ‚ç­”æ¡ˆ
        clean_response = self._extract_final_summary(response)
        print(f"  åˆ†é¡å›æ‡‰: {clean_response}")
        
        # ç¢ºä¿å›æ‡‰æ ¼å¼æ­£ç¢º
        if "Form Mode" in clean_response:
            return "Form Mode"
        elif "Info Mode" in clean_response:
            return "Info Mode"
        else:
            # é»˜èªç‚ºè³‡è¨Šæ¨¡å¼
            print(f"âš ï¸ ç„¡æ³•ç¢ºå®šæ–‡æª”é¡å‹ï¼Œé è¨­ç‚º Info Mode")
            return "Info Mode"
    
    def _extract_final_summary(self, response: str) -> str:
        """
        å¾å›æ‡‰ä¸­æå–æœ€çµ‚æ‘˜è¦ï¼Œè‹¥å­˜åœ¨å‰‡ç§»é™¤æ€è€ƒæ¨™ç±¤ - èˆ‡mainç‰ˆæœ¬å®Œå…¨ä¸€è‡´
        
        åƒæ•¸:
            response: æ¨¡å‹çš„åŸå§‹å›æ‡‰
            
        è¿”å›:
            ä¹¾æ·¨çš„æ‘˜è¦å…§å®¹
        """
        if not response:
            return response
        
        # æª¢æŸ¥å›æ‡‰æ˜¯å¦åŒ…å«æ€è€ƒæ¨™ç±¤
        if '</think>' in response:
            # æ‰¾åˆ°æœ€å¾Œä¸€å€‹æ€è€ƒæ¨™ç±¤çš„çµå°¾
            think_end = response.rfind('</think>')
            if think_end != -1:
                # æå–æ€è€ƒæ¨™ç±¤å¾Œçš„å…§å®¹
                summary = response[think_end + 8:].strip()
                return summary if summary else response
        
        return response
